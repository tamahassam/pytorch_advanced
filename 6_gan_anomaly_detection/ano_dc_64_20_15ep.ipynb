{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3SuZ-jXhNTRE"
   },
   "source": [
    "# 6.2 AnoGANの作成\n",
    "\n",
    "- 本ファイルでは、AnoGANのネットワークを実装とAnoGANの学習をします。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGPAU-EpNTRF"
   },
   "source": [
    "# 6.2 学習目標\n",
    "\n",
    "1.\tAnoGANでテスト画像に最も似た画像を生成するノイズzを求める方法を理解する\n",
    "2.\tAnoGANを実装し、手書き数字画像で異常検知が生成できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cJuKeVRNTRF"
   },
   "source": [
    "# 事前準備\n",
    "書籍の指示に従い、本章で使用するデータを用意します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3LCPGrVNTRG"
   },
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUnJkIgSNTRJ"
   },
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZygEkOn_NTRM"
   },
   "source": [
    "# Generatorの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gen_lyr:\n",
    "    def input_lyr(z_dim, image_size):\n",
    "        lyr = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, image_size ** 2 // 8, \n",
    "                              kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(image_size ** 2 // 8),\n",
    "            nn.ReLU(inplace=True))\n",
    "        return lyr\n",
    "\n",
    "    def hdn_lyr(image_size, i):\n",
    "        lyr = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * (2 ** (i+1)),\n",
    "                               image_size * (2 ** i), \n",
    "                               kernel_size=4, \n",
    "                               stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * (2 ** i)),\n",
    "            nn.ReLU(inplace=True))\n",
    "        return lyr\n",
    "\n",
    "    def output_lyr(image_size):\n",
    "        lyr = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size, 1, kernel_size=4,\n",
    "                               stride=2, padding=1),\n",
    "                nn.Tanh())\n",
    "        return lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=20, image_size=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_lyr = gen_lyr.input_lyr(z_dim, image_size)\n",
    "        self.hdn_lyr2 = gen_lyr.hdn_lyr(image_size, 2)\n",
    "        self.hdn_lyr1 = gen_lyr.hdn_lyr(image_size, 1)\n",
    "        self.hdn_lyr0 = gen_lyr.hdn_lyr(image_size, 0)\n",
    "        self.output_lyr = gen_lyr.output_lyr(image_size)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        out = self.input_lyr(z)\n",
    "        out = self.hdn_lyr2(out)\n",
    "        out = self.hdn_lyr1(out)\n",
    "        out = self.hdn_lyr0(out)\n",
    "        out = self.output_lyr(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WyU7Yx0KNTRS",
    "outputId": "2c3e3f01-79fb-467c-b6f8-481ca9038741"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA970lEQVR4nO29e9zlY/X//7qSU6SIGaeQjyFS6DMm5VMf5dCEohxyphxDDumDoRKRcUjOhylqQqn4OIQcmhw+OshUFEUTphKZUqSSMq7vH7P3dT/Xa+77nnHa9/x+e70ej3nc676va+997fd+X7PXul5rvVaptSqRSPz/Hy8b6QUkEoneIDd7ItEnyM2eSPQJcrMnEn2C3OyJRJ8gN3si0Sd4QZu9lDK+lHJfKeXXpZTDX6xFJRKJFx/l+fLspZT5JP1K0saSHpJ0h6Tta62/ePGWl0gkXiy8/AU8dpykX9daH5CkUsolkraQNORmX3TRRetrXvMaSdJ8880Xxv7xj380+5WvfGUYm3/++Zv917/+tdmveMUrwrwFFlig2U888UQYW2SRRZr9t7/9rdm+Dr62P8ff//73Zi+++OKDPp8kLbnkkkM+x1NPPTXoa/n6+Z/wv//97zCP73vmzJlh7J///OegY0sssUSY9/TTTzeb195/5zpGjx4d5nHs0UcfDWNLL710s1/+8oHbjO9fkkopzV544YXDGOfOmDFj0NeVpJVXXrnZ/ln85S9/afaCCy44qC1Jiy66aLP/9a9/hTH+7mt89tlnm+2fBTHUZ+tr5v3t15v3n6//mWeekSQ99thj+tvf/lY0CF7IZl9O0u/w+0OS3jLcA17zmtdowoQJkqRXvepVYezOO+9s9n//93+HsVGjRjX7u9/9brPXWmutMO91r3tds6+66qowtt566zX7+9//frNf/epXh3kbbLDBkM/xox/9qNnbbrtts7/3ve+Febvvvnuzv/3tb4exn//854O+liQtv/zyze5+eJL0yCOPhHlvfvObm/3nP/85jN13333N5o2zww47hHkPPPBAs3ntpfg++R/Nxz72sTCPa/z85z8fxv7nf/6n2dz4P/vZz8K8l71sIJL0z/Puu+9u9plnntls/ocmSV//+teb/YMf/CCMXXLJJc1ebbXVms3/ICTpv/7rv5r929/+Noz95je/afab3vSmMMaN+vjjjzfbN/SKK67YbP9P4dZbb232lClTmn3wwQeHeVOnTh30+aSB++D444/XUHghMftg/3vMFhOUUvYqpUwtpUz1/3UTiUTv8EK+2R+S9Fr8vrykh31SrXWSpEmStOyyy9Y//OEPkqQ11ljD5zX7P//zP8MY59KN8m/UD3zgA82meyVJ++yzT7Pf8IY3NJshgiStuuqqzf7hD38Yxt7+9rc3+7WvHXjrF154YZh3yCGHNNvdZ772xz/+8SHHPvjBDzZ73LhxQ67Dv9n57fXrX/+62XSDpehx0OuRpE022aTZRx99dLN//OMfh3n89v7lL38Zxnbaaadm89twzz33DPNuvPHGZl900UVhjL/z23zTTTcdch18XSneBwcccECz6W1I8VrddNNNYWyrrbZqNu8jSdpjjz2affvttzf7iCOOCPN4b37rW98KY/RGjjvuuGZvttlmYR7vqy9+8Yth7NBDD5U0u3tPvJBv9jskjSmlvK6UsoCk7SRdNYfHJBKJEcLz/mavtT5TStlf0vWS5pN0Qa31nhdtZYlE4kXFC3HjVWu9VtK1L9JaEonES4jnzbM/H4waNap2Y1E/pWbsdv7554cxxpTjx49vtp9W7rfffs3+0Ic+FMbWXnvtZp944onN/v3vfx/mkXbyuIiv97nPfa7Zfrr6zW9+s9lOSd11113NvuGGG8LYlltu2WzGlH52wPjYGQP+/oUvfKHZn/70p8O8ww47rNkf/vCHw9guu+zSbB6qHnnkkWHe2LFjm73ddtuFMZ59fOc732k2Y1cpnlP4tdpxxx2bvdJKKzXb436yDn6GwdN/3kf8/KTISPAek6Svfe1rzd55553DGO9jnnW8733vC/P23XffZvv9QmaH5yJLLbVUmPe///u/zd5mm23C2HXXXSdJOvbYYzV9+vRBqbdMl00k+gS52ROJPkFP3fgxY8bUU045RdLsCRpcRzfxpovLL7+82SussEKz11xzzTCvSz9IsxJ4CLpHpK6mTZsW5jEh5hvf+EYYYzIO3TR/L6SMHn44spF01a+++uow9qlPfarZzPj7yU9+Eubxepx77rlhjO7uu971rmaTypOiW8/EFklaaKGFms3EGU+Iufnmm5s9ceLEIccYhiy22GJhHt1n0nxSTBBaZZVVms2MPEnabbfdmk1XWoqU2gknnNDsww+PpRwXXHBBs5m4JUnveMc7mv3kk0+GMd4HzJzkNZSk008/vdl06SVp2WWXbTbDC08823rrrZtN6lcauN8PPvhgTZs2Ld34RKKfkZs9kegT5GZPJPoEL4hnf66otbYY8I1vfGMYY6xJmkyKsedDDz3U7KOOOirMY5rjMsssE8ZId9x2223NZrqjFKvUWAAhxSqsvffeu9mkiKRYuLL//vuHsQMPPLDZH/3oR8MYU4FZqME439fP6ybFSqlf/GKgANELRFjsss4664SxSZMmNZsFNGeffXaY9973vrfZHufy+bfYYotmO/V23nnnNfuss84KYyxsYuGOx+WkUr1CkPQgz2q86IZULWNvKRad8LWkSBcyzdvPJnif+TkR08E32mijZrNoSpKWW265Zl9xxRVhrPs5efo3kd/siUSfIDd7ItEn6KkbP//88zdX5KSTTgpj119/fbOnT58exihwQNfmj3/8Y5jHbLiDDjoojLFG+Xe/GyjDZ1aSFOuanb4jxfPZz3622Z6BdtlllzWb7qw0kOkkxfpkKdIznOcUI939j3zkI2GMbjKzrLxyjm6910DTTaab6lV6fG90lyVp++23bzZdy9VXXz3MYwjkYiQUlGBmIzPapOG1BR588MFms2KN1KAUsyVJbUrxWjkdS+qT783DVFK/Tqndf//9zSb15lmJvL9/9atfhbGuOIbTqER+sycSfYLc7IlEn6CnGXQrrrhi7WYu+Uk6XWbXAPuP//iPZtMV6wphdEE3mCfWkrT++us3+//+7/+a7ZJPlDhyd4uuKdfhhRl0W3n6LkUZrNNOO23INTLjjafIUnTr3//+94exyZMnN5un2e4i82TXdfLIZHBNXrzE311whJlxzBBj+CPFcI6yTlJkXniiP2bMmDCPmXdeqMJrTHecclVSLKbxz52FR54Zx0w2hqIuUMH7nYVSkrTXXns1m9eArIgUw1vuCWmgcCoLYRKJRG72RKJfkJs9kegT9JR6W2SRRRoF5BlXzE5z2WOKH5CaYIaYFOMdxq5SpOz4OFY0SVF0weNt0lrUXXcxx69+9avN9kwtiku4ZPZPf/rTZjOm9IwuxsqsDJMirci436kaxvBOm/EcgNdjuGowz1w79dRTm03ayeeRAnNJa2b2UUTDVYpJnzpte/LJJzeb19vPKXhO5J8npbs9M5PgdSN1KsV7zgUzeZ+xyvDKK68M80hTnnHGGWGsm33ofRCI/GZPJPoEudkTiT5BT934xx9/vAk2eIEIs71cP3zXXXdttmeCEdSxc/eWdBgpKace2dnEu38wo4l68KRcJOmWW25ptrtsFCCg2y7Fgh/qwLnYATvkeEcb6paxeMS7qNCddlqOWVh0falbJ0X6zikpfhYsmPHrzQw0/8z4Of3pT39qNilWKYZGdLml+D4ZDrrWPzXlvciEmXEUGJGiLj2Ll77yla+EeddeO6DL6m2/GGJRVINiLFK855hdKA2EYhQ9ceQ3eyLRJ8jNnkj0CXKzJxJ9gp7G7K961ataRZXHmhSZZPdOKRb7U8DRNcJJfTgFwZiPcb+naJL+ccqLdNs111wz6OtKMW5yqonChhSwlGLsz5RQUnlSjHtdBJKx8qWXXtpsCmlKUVyB78XXzNbUXlHGLrReKUY6j2nNrj1PeGdVnhGwKo2fpRT7u7EjqhTjb+rBu44+PzOPe3n/uVgIhVZ4HT3u5/mP3xOkmnl/eD86rt9FTrt05HBto+f4zV5KuaCUMqOUcjf+tkQp5cZSyrTOz8WHe45EIjHymBs3/suSxtvfDpc0pdY6RtKUzu+JRGIexhzd+FrrraWUlezPW0jaoGNPlnSzpMM0Bzz99NOtUP+xxx4LYxtuuGGzvZ0z3R667q9//evDPGqEuztHMQGKYWy++eZhHqvevO0zXVrCtepYVefUGyvWnFoh/cPsKReooKvmYcjb3va2Znc1+qXZRSOYWeZ0GFsgM9Tw0IvXim2cpJjhxRDC6TtmvDmlxvvgL3/5S7NdLITCFt4im2Ik/NyZsSlJ55xzTrM9M5OfO8MkKbZYZnUc72cphjJ+He+5Z6AfKt3zL33pS2EeXXy/97thjt8PxPM9oBtda31Ekjo/R81hfiKRGGG85KfxpZS9SilTSylTWTOcSCR6i+d7Gv9oKWWZWusjpZRlJM0YamKtdZKkSZK08sorN3+RBRtSPJE85JBDwhiLSW6//fZm+8kjT895UixFN4riBNQvk6J75J0+2caI7qK79xQjoLSzFMOQBRdcMIwxm4zPv9lmm4V5PC12OWqedrO9lHcmZWhEgQopMhIMQ1yQgdl66667bhjj48hWuJu5/PLLN9v13Y499thm87N295YFOt7dlNeKmXyegcYsQs/gZMabj33yk59sNu8/F2ChOIt3eKVOHtfhYc173vOeZvt17Iq1eJEQ8Xy/2a+S1M1h3VXSlcPMTSQS8wDmhnr7mqQfSFqtlPJQKWV3SRMlbVxKmSZp487viURiHsbcnMZvP8TQhkP8PZFIzIPoaQbdAgss0Fouu2ACs8Sc+mDLYgoPUhRBinEY2zNJUZvbq8gIZkQ5bcb4mJlUrC6TYlzuwpqMtVzskvQgqSHXOCeV5e2LGdvybMI135kVxko/SXrLW97S7K4euTQ7Xcrn9GowaruTGvPsN762V0KyFRKzKr21EsVFWREoxbOh4dZBSs0139dbb71mO01JLfe3vvWtzWalphQzDL26j2c1zCLcb7/9wjy2qHKt/24Vn7fGIjI3PpHoE+RmTyT6BD1142fOnNn0ub11EykD6oBLMZNquO6jdNU9FKBrxiyzI444Isyj/ph3HKX7TwrQKSnO82IGrtG1v+n6MkQh5SdFColtraSoGUdKx7O26OIz80uKIg+k6FzM46677mq2ZxsytGHI5pp8pM28A+kxxxzTbGa/uSs9ZcqUZh988MFhjPQjX8sLSSg4Qr16KYZevHekSFPyPXvrJq7R3Xi2FWOY6oVSN9xwQ7Od2utSy15kQ+Q3eyLRJ8jNnkj0CXKzJxJ9gp7G7P/4xz+a2AKFFaRYaeX0AWPZiRMH8ndcuIH0naeikkIiLeepi4yHqTUvxZRH0nDDpUZSYFKKFVus5JKiuCOFEDwOZUzpQo9MJaXooaftUjedQpdSpMOoX++ilcS9994bfmeaKqmxVVZZJcyjuKXH4lwzW0d7bL/VVls121OL2YOO5xaeisozB7+mvJdcy33jjTdu9k033dRsP0vhuQgr8SRptdVWazYFUlzE5cknn2y2fxZnn322pNkFXYj8Zk8k+gS52ROJPkHP2z91db29xS+rz7w1MEtjqYPmAgF0652WY3YTdbpZdSVFCtBbQrNyjKGFZ7HRHfVWQqR/htM6Y5tmilpIkYZyYQtSb6QAnXpjpdsee+wRxrouoRTbHLsmH11Vb6PFkISZgsNleHnoxSw3urestvPXYvafFLX5GV6xgkyKGWn+uVCvjsIkUqTK6GZTHESK15/tqqRIA/J6s0W4FEVSWFkpDYiAeEhJ5Dd7ItEnyM2eSPQJeurGP/HEEy0LyN1stjvyk/p99tmn2Sy+OO2008K8v//9783mKa8UM6mYNcfnlmLmkxfrsDCB2U1f+MIXwjyelru7SPfcs/woXMDsN3cJ6U6feOKJYYyPu+yyy5r92te+NsxjYQa1+6RYkMJQyQty6PoytJDi9Zk6dWqzvfURCz88O43ZYDyBd9nqk046qdku3sAiKl638847L8xjcY0zCxzzTrPsusqwybNAea2c/SDrQJeeGYQO16DrshB+gk/kN3si0SfIzZ5I9AlysycSfYKexuwLLrhgE33wTKodd9yx2S7qRwHKnXfeudlOvVFkknrkUmz/y9iTVJgU4zO+lq+DWVZOa1E8k9VxUozLXSSB8SBpKBcqIChoIEW6kBSm02asHqQ4gxSzDXnm4JrspBW9ddM73/nOZpPe9HMKtuJyMQ9mlnVFT6TZBT4Zw/v15mdD2syrw1iNx6o/STrwwAObveeee4YxZlJ+5jOfabYLWvJ+ueOOO8LYlltu2WxWwPk1ZValnwV1783hshzzmz2R6BPkZk8k+gTFiw9eSowePbp2XdzrrrsujNFFcR0xti5i8QiFICRp2WWXbbYXBFAogq6jF0TQXWTGlRT1xuj2uUvF0MCLdZid5RlS1CKju+80IukeF9ig9jrpMNd1Z2GJt6+i68ssNm/xRJfchThI5zHjjWuXYuadt1ZiKEMRkHe/+91hHmkufn5SFOngveN6egw7vJfAmWee2WwX8KAISzc71P8uxRDQW3ExLGF4RepUiqGudynuip0cffTRevDBByMP2kF+sycSfYLc7IlEnyA3eyLRJ+gp9bb44os3oQGnk6ivzv5ZknT++ec3e8KECc2mWIAU41ynw0jLsYebp2gyRvX4kimgXBP1zf21XQud1J5XyzH+vuKKK5pNcQYp0jiu187+aJ/97GebTVpIipVcpNp8zTxjcDqJIiBsRe2Poxa/X1PSba5tz5RQrp+94/xx3tOO+u0HHXTQoGuS4rV3Spcx9gc/+MEwxjidZ0FejUjNera6luK5DlOtXc+f1Y8PP/xwGOsKlfhZBDE37Z9eW0q5qZTyy1LKPaWUAzt/X6KUcmMpZVrn5+DNyxOJxDyBuXHjn5F0SK11dUnrSdqvlLKGpMMlTam1jpE0pfN7IpGYR/GcqbdSypWSzuz82wBtm2+uta423GNXXXXVetZZZ0mSlllmmTDG7CavrqIGG6t6qMUtxeozz9Cju043yikMulGkbaToPjMscHeLWVWu/c0KJ6e8KIRAbbPuNeuCtBm15KTYGoqVYtTWk6LL6ZpoFObgGIUVpOgKeyYfPwteA9f8Y8aX05SkNHmt+P79OVx4gmIWpAq9WpDhEFtvSTF8cVqOdB7fJ+k6KVazeYYeKxL5mfm9yVZW1PWTBlpVb7jhhrrzzjtfOPVWSllJ0jqSbpc0utb6iCR1fo4a5qGJRGKEMdebvZSyqKTLJB1Ua/3rnObjcXuVUqaWUqb6t1Aikegd5mqzl1Lm16yNfnGttSug9WjHfVfn54zBHltrnVRrHVtrHetucSKR6B3mGLOXWTmXkyX9udZ6EP5+kqTHaq0TSymHS1qi1nrocM+15ppr1m4KoKcCsl+a905j6ivTVJ3eYOzmbZTvueeeZrNHmVNBTNWlyKEUK6WG0jSXYoUZK5qkKOboqi08E2D852cY1Eb3Ki9Sh4w9XaCQ1+64444LY6SaqHdOlR1JuuqqqwZduxRTXVkp1o0tu2CKs1OpFAZlerXTS6yq85idnw0FMpdbbrkwj3Qp1X6k+Dk5/UixS56X8NzDf6ewqBTj780337zZw6VrD9VO/Nxzz9Xvf//7QWP2ueHZ15e0s6Sfl1Lu7PztCEkTJX2jlLK7pN9K2mbwhycSiXkBc9zstdbbJA36P4WkDYf4eyKRmMfQ0wy6P//5z82d8bZIdDM9k4otbumWuegeXWYXgSSV9cUvfrHZbActRXFEZvVJscqOrp0LZZBKodsuRR1zf22GFKSd3M1mtprr77O9MCvA6BJLkTr01lCkf2bOnNls19HnPFbsSTHTkeKOLv5Al9ldU1bZ0fWl5r0UQw138RmS8HNyeo20lotWdgVXpBgmSTHcomiJtw7jvcmWWlKkHBlueiYpRS8OO+ywMNYNx71Cksjc+ESiT5CbPZHoE/RUvGKNNdao3U6rhx56qI81m660FN1nupLezZNuMN1ZKZ6kUyjDRS6YJeYZXdQTZxGLty1iVhXdYCmeFrNzqBSZBmaMscBHGhAqGGyNdEHZaslbPFHMgh10pVhMwlDAWzcxG85pVRZ+MFvywgsvDPMoROHuLd16hm++DoYCninIz5qfmbeQ4kk3XXoptg5jhqUknXrqqc3mabx3e2ULMw81GMKyCMezQFmw5GzTwgsvLGnW3nnyySdTvCKR6GfkZk8k+gS52ROJPkFPqbe//vWvTVSQ8akU+7YxJpUilcX4iXGW/+5tcQlWIHnMTu12Ui7SQFwkxX5dpPKk2LKZApBSpIJcQ51nFaz0c4FFii96xhjBeN7rEthPz7MImQHIeX52wDMMP7dg+2JSe55Bx55/1ImXYu8+nsE41UmhD2YXSpEOI5Xq1Bi18z37jRlu/vxf+tKXmj1x4sRme1Une865Zj2v/4orrthsZnpKkWKkSIk0QO3x/Trymz2R6BPkZk8k+gQ9dePnm2++RtE4JcWMIG+PQ/eceuQ+j5rbrrnG12NY4C2H6I56m2NmcZGu8jZOpN6c8iI15q4vizEogOFuPAt+vCUT9fDo3ro2G3XMHaQ36Y66+8lrQGpJiu4u9eDpzkoxA9DbbdGNp5acr4MiD66jTx0+FtMww0+K9C7DPGn2+4Cgrh2189kySoqZk05TMhOUhU3esplr9nunG2p49h+R3+yJRJ8gN3si0SfIzZ5I9Al6GrPPnDmzUSiMvSXplFNOabZXRjFeY+zjWuX8fZ999gljjKcYA1N8QIoVVS5e8eUvf7nZTJN0DXLSJ/4crErySjGmfTJ+9fiaNOUPf/jDMHbCCSc0e6gzAB9zmoippBQSYT80KVJSXlVHXXOKfbqIImNMTx8mtce4dtKkSWEeU1ip5y/F98lzhH333TfMI63I+81/97Mg9vXjGQnPbaR4ruPnG3zfu+yyS7O96o0xu581dYVB//Wvf2ko5Dd7ItEnyM2eSPQJeurGSwPZZd/73vfC3+kOuSvGlkmkndx1ZGjgGndsGcRMLa+wo+gFWwFLMaOOYgR076VIJ1HnXop65V75R6qFazzjjDPCPGa1eRXW5MmTm83sOrZGlqL+uVOHDEuoG3/ttdeGeRSXcGqP2V6c59VmdEeHy8JjViLbTknSOeec02ynq66//vpmU8ud4aAUq81cZ67bWkmaPWuTLZz5ObluPEMZ11iky89QYOzYsWEehTJuuOGGIdc4FPKbPZHoE+RmTyT6BD1145999tnmhnuSP4v9vZUQXW1mybnwBt14uvtSPMmkyMAtt9wS5vHklRlcUiySobvoUs/MBnTGgKelnqlFV48urEtV8+TYBTz4fihF7KIRdN2ZZSbFIhHKRdOWoq6fn6TzdxaLuBz1yiuv3GzKSvvjeE+4Bt1uu+3WbG+pRWlmFiV5hhvbP7HgSZIuv/zyZp9++ulhjF1cqRvo14rdXxmWStGNpyAI1y7F+52n9tJA4RfDFkd+sycSfYLc7IlEnyA3eyLRJ+ip4OSqq65auzGPa5WzgN8FJagjz8w114ZnNtZJJ50UxiiIQWELp+goNvi6170ujLHKjlSNx+yMt6l5L8XYzekqVjyRUvNrxQw9p96YoUfq8PDDDw/zKL5IUUkpaspfcMEFzXZqjOcis7qEDYDUEGNZz8JjbOvtnHk9KGDJ9t5SpAedgqJuP6vlvGKS18Or6vj8XsXI900qdaeddgrzSNnx7EeK5wysEPS+CBTfcPqx285qk002ef4tm0spC5VSflRKuauUck8p5ejO35copdxYSpnW+bn4nJ4rkUiMHObGjX9a0rtqrWtJWlvS+FLKepIOlzSl1jpG0pTO74lEYh7Fc3LjSymvkHSbpI9I+oqkDWqtj3RaNt9ca11tuMePGjWqbrXVVpJm12Zj5pe7c6TA6G55Kx5283SQqvjwhz/cbNcbI43D7CgpUj7MwGJ3UClmyXnBBfXxna4aM2bMoPYf//jHMI8uqGuOUWjh85//fLNd1IDuvxfakAalW+whA8UrvCMtM+NINXnIQPfWNe7oIrPDK8MCKRZOeaEK18Fr4/c9qTfXmWOxlF9HUqmk7KjxLsXQgGGYFKllaso7Bc0CIKdju3vhiCOO0AMPPPD8deNLKfN1OrjOkHRjrfV2SaNrrY9IUufnqGGeIpFIjDDmarPXWmfWWteWtLykcaWUNefwkIZSyl6llKmllKneTC+RSPQOz4l6q7U+LulmSeMlPdpx39X5OWOIx0yqtY6ttY71zKREItE7zDFdtpSylKR/11ofL6UsLGkjSSdIukrSrpImdn5eOfSzzMKiiy7aqq88HqG4BLXEpUhtkbrZb7/9wrwtttii2Z6KOm7cuGYzzho1KkYf1KX3mJpUE2M+9oeTomCjC0ISTlcx9ZKpki5iwMf5GpkyTOrNaTOKSHjvNI6x8opnAFKktVxAlLrmrAr0FFCOubAjz0KYduytoxkfH3/88WGMMTtTi721MdfvKb0UIHGhD2r4M63Wtfj5ei4kwipJngW5jj7H/Pyke87isTwxN7nxy0iaXEqZT7M8gW/UWq8upfxA0jdKKbtL+q2kbYZ7kkQiMbKY42avtf5M0jqD/P0xSRvO/ohEIjEvoqdVb6WURp1R3ECK7ZQorCBJ22+/fbOZXefuJ/XGPEygVhvdI2YsSVHX3DPo6LrTpfesMD7nySefHMZIPXn7J2aJkf5y9/bb3/52s6kDJ0XBCl4Pp4LYhsrFQkiLdqlSaXahD4poeItiagryYNbdZ1a2MTvS5zKrz11VasV75hrFMuj+O73G0M7beVGzkJ+RFDMzGSYwbJTi9fGMSN4jXP9wOoousNGljJ2WJDI3PpHoE+RmTyT6BD0thFlzzTVrt/CErqgkHXDAAc2m+ylJ99xzT7OZYeSSv8xOc5qP7hY7yHrhBFvzuHtOkYFu4YEUC3Wk6J57NiDdL578SzET7BOf+ESz/QSYHUc9FGCYw9Nsly/mOh544IEwxlCAmXEeCjCz0VkBFgqxeMTDNzIo+++/fxhjtiS72nonWLrIrgfIYilmInrIwIIfZ0kYsvlpP0MgFlFRIEWK+nELLbRQGGOHWhZOueAIw0/vQtvdM4cffrjuv//+559Bl0gk/r+P3OyJRJ8gN3si0Sfoacw+evTo2hVvcOEJUmNOeZF6YmaW68a/5S1vafbWW28dxiiOSPGDn/3sZ2EeBRBZASdFqolxF88UJGmVVVZptgtOMttuySWXDGPM9mIFmMehO+64Y7NdlOJzn/tcsxmHfuQjHwnzpk+f3myvqmMFImNxz+TjWYJTXl//+tebzXvM4/Lzzjuv2d7O+atf/WqzWZXmIpuk9vwchFVw1Pp3cRN+Tk6b8YzAhSR5vkH9+uOOOy7M4/mPf548M6H2vAtl8Ho75do9yzrmmGM0ffr0jNkTiX5GbvZEok/Q0wy6xRZbrOmueXYQXVMvRGCrKHYH9VY8dDOd+vjOd77TbLqmpOGkmLVFl95B4Yz3vve9YYwFC95CikU+3kGWbj1deqe8KAbhwhMMX9h6youGSAW5SMdFF13UbFJerutOuvSaa64JY9Sip2Y/9dykGJa5sAVpKIYCTo3xd7aakuJnQ1rVrxtDNrb5kqKQiHfsZfYe9QWdGqOeu7/PadOmNZuuO8NBKVKurnvY1b/zXgdEfrMnEn2C3OyJRJ8gN3si0SfoKfW21lpr1W6arAs+kP759Kc/HcaYEkrKi3SaFEUBSOlIMU6iCINXMfHswJ+fMSqvG8UepEgheVtmvhevfiKNdt111zXb6SrSS/7aPHPg2YRrobNFtqf0cu4TTzzR7Pvvvz/MY/qmXyvSp3vttdega5LiWYrTZtTVp4DEjBlRFIlVYy6wwdejlv2qq64a5lGs1Kvq+Jk5Hcv7linUrKKTIr3m7ZyZ1kzazyk6Ck46Zdw9e9pmm2109913J/WWSPQzcrMnEn2Cnrrxq6yySu1meDltxqwoXxN13klHuJgCdb9c33ujjTZqNmkoap9L0e1zF/nWW29tNlv2MHNPirptrISSojv3rW99K4yRQmJLYafN6HZ7i2Jq7zFrzl1Caq65i89qM9JwO++8c5hHF981/BlO0N331l5ch+sGMgOQWY+eWUbtN69mI+XFTEenM9ne2rPT2IbJqS2KRTAk9Oo+VnkyJJGiBh0zIJ16YzXoJZdcEsYOOuggSbP2yr333ptufCLRz8jNnkj0CXqaQTfffPM10QS2SJJiZ1V357ry01KUW/bTbGaWMQNNiqejdPe9cQUz9Kj5JcVsL+rMDddayd1bZpa5K0YmgNledKulqNvGE2Apau+xCyqz+qTZ3ViCoQyLQDzbkIIYnhlHl5nMggs3UOLar+Nhhx3WbIYrU6ZMCfMo/uCuL118vtbEiRPDPOrTeTsvZtt5piDddTIcV199dZhHMRWKoEgxXFx88YH+qMOJdDBzTxroDDtcI5b8Zk8k+gS52ROJPkFu9kSiT9DTmF0aiE+86ohZZ4w1pUhvMH6nWKEUBSi9Eo2ZWszu8tiVlUUu0sgMsosvvrjZw/Ww81bGjDed2iP1Rr32rkhnFxRJcGqP1BCr2bwajKILFJqQopAI3zOr16RIyzn9yAo5vpavl9SYXyu+NukpnttIseWVZyxuuummzaYevj8HM+Fc4JNxP0U/pChSQTHK4YQnPMuP9yZFNby1MyloFxrt3i+uy0/M9Td7p23zT0spV3d+X6KUcmMpZVrn5+Jzeo5EIjFyeC5u/IGSmClwuKQptdYxkqZ0fk8kEvMo5sqNL6UsL2kzScdJ6vJiW0jaoGNP1qxWzof5Y4mnnnqqJfC7lhddNmYRSdF1YjaWiwxQrMFdTmZBUTSCwhiS9KMf/WjQx0hRa50a7y6m8P73v39QW4q6agxJpNh2iNSkF6rssssuzXa3mFlcfC9emEHa0jX8KdBAKof0qBSpOLrIUtQ8J43odJK7xUONkWL01kcstDnhhBPCGNtcsaPudtttF+axH4FnJZKye/LJJ4d83C233NJsz5Lj4772ta+FMbY3I6XGXgdSpJaZUSgNhAnDhZRz+81+qqRDJbFkaXSt9RFJ6vwcNcjjEonEPII5bvZSyuaSZtRafzynuUM8fq9SytRSylRPmkgkEr3D3Ljx60t6XyllU0kLSVqslHKRpEdLKcvUWh8ppSwjacZgD661TpI0SZJWWGGF3lXdJBKJgLnpzz5B0gRJKqVsIOnjtdadSiknSdpV0sTOzyuHeo4unnnmmVb1RA12STrqqKOafeSRR4YxxqykNLyVMdNUvXUt6SqmV3o1GMUJXA/+9NNPH/S1mOYqxRiVryXFdEun3hhvkfZzwQfGchQrlKLAAau3nNbi2Yf3quOaKeLp7a0poOBpmksvvXSzWcXorZ2POOKIZrNaUIo0Eqm8fffdN8xj/wA+nxTPI3jG47Qtrz2voSSde+65zeaZixQpXp7/eFrt3nvv3ew77rgjjPGcga3L3/a2t4V5TLX+5je/Gca6QqZ+pkC8kKSaiZI2LqVMk7Rx5/dEIjGP4jkl1dRab9asU3fVWh+TtOFw8xOJxLyDnmbQzT///M0do1stDRTfS7PTcnSrWJ3kLssxxxzTbLbZlWI7Z87bdtttwzxWxDGbToraZ6xOckEGZpZRS1yKNI6vkY+joITrjLOiz9tosdqK9N0VV1wR5jGzzCvnWDlGaokCD1LUU99ggw3CGCu76N6uv/76YR6pQwqMSJFeIrXnYh4Mo0aNiqQQ22hR25DVjVKkY71V90033dRspw4ZGjCkIs0nxXvVM0SZfchMPt6zUgxn77333jDW1eHze4rI3PhEok+Qmz2R6BP01I1/+umnW6acuzJvfOMbm+3F/TwBZVsd75T54IMPNttPn3ky7ZlgxGmnndZsutVSzGDi6bA/H5/DNe64ZhaISLHYg6yAy11Tr4+CCZK01FJLNZvyyKecckqYxww6F8fg+2Z45afI1ABkFpsUWQ6GFp4VRrfTO9LyGpD98KIbFg25tiHDHBZA+XNQsILiIFIMPdw9Z5YlpbCdbWL4xrBAihl0LJTqClJ0wUIYfs7SwGfh9wqR3+yJRJ8gN3si0SfIzZ5I9Al6qhu/wgor1G62FqkrKcZyG24Y6XvSKYyHPdeesb3Hw6SXmBnnWXikZFwIgO2DGA97phMrnvz8gY+jYIcUBRZJPw4Xh/qZACvCGCdS4EGKNBrnSVHPnvGqn5FQaMEz4xhH81yBmXtSFMh06o20Fm2Pm0kB+v3MsxvSX36GQVrLz5NYIef3BKlgUm8uwMnKSG8hxetKKnjdddcN8z7xiU80m6If0sC1Gz9+vO66667UjU8k+hm52ROJPkFPqbeFF1646aI5XUU6Yp999gljb3/725tNN8215+kWszhCirTOkksu2WwXf6AmnWt/0x2lq0vNNikWwtBNlSLFeN9994Uxur7sTMo2TlJ0M13Y4vvf/36zWVDk4QrdSg81GDZRpMOvB7XXXSyE2Wqbb755s71g5vzzz2/2cBmLBClWKYZznm1I3X5mJXrPAQqf8POT4rWiKIcUC4WoC7fmmmuGefws/DkolsHuxt5CilmPLoDRDfW8lReR3+yJRJ8gN3si0SfIzZ5I9Al6GrM//vjjrfqKwgdSTD91gQBWAjF90+MzUjecJ8V0S9JE3s+Ncf/48ePDGOkrpkZSoFGKKYuuH87n98cxvmcqqot5UDyS5w9SrDDjWQdTRaUoiEFRDimKWTCW5WckxXjV4+uhKDuvEORzbrbZZmGMFCnPdPz8gecF3uOPopvnnXdesydPnhzmMRXVx7rCENLsPfNIW1JUw8+Cdthhh2b7taIuPSlov1Y8G/I+gd2zJhe6JPKbPZHoE+RmTyT6BD1145999tlGvbh4BdvjOG3BDCnSP67JznbArj1PUQpm19HNk6JggFeDUbeM7pa7yAwnnCKhe77yyiuHMbpgrGxznXTqpVGrXJIeffTRZpNS8+c49dRTm+1ZYaSamKHnlVwMxVzYgpQa20u9+93vDvP4Pv29sE0S7w93YVk15u28zj777GazNZbrrjNM8BCTlZakv6Soy8dQwN1p0raezcisSral8vuDoeNQ98RwCs75zZ5I9AlysycSfYKeuvGLLLJIy5Jy7TS6u64PRhecrql34uQpp0vt0jWlLpkX3TA7a+ONNw5j1EFjQYef6LNghhlRUixucJEEnuJTEtmfg2PUi5NipiAfR3dZiqGAt39i8ciWW27ZbHfBv/KVrzT7U5/6VBhjB1LKLbuEMz9rb1FFl5Qn0/65sA0VC6Wk6JJ7YQnBQhtv58V1edEQT9nJfrhWHUU6/BpQAGPVVVdttktaE85EdTPn2BHWkd/siUSfIDd7ItEnyM2eSPQJehqzL7DAAi1jylvrMlY+88wzwxjpHwpFuEAAK8o804mxOVsj8zGStPPOOzfb2zmz0o3P79QVs7gYx0lRh33cuHFhjBlk1EZnSyAptmdiPCxF+ocZeTNnzgzzjj766GZ7lRfPPnj+4LEsRTU83mZs+4Y3vKHZrlFPepPzpPhZX3bZZc328x5mljldypZJPAOgUIgUaVvPXCNlR2FKKVYF8hzE18isUL6WJB1yyCHNvu6665rt+vWk7F796leHsW7lnJ/NEHPbn326pCclzZT0TK11bCllCUlfl7SSpOmStq21/mWo50gkEiOL5+LGv7PWunattdt973BJU2qtYyRN6fyeSCTmUbwQN34LSRt07Mma1QPusKEmS7OopW4hiHc3pZ7ZTjvtFMZIJ1BX21sJsSsqhQSkKKbA7D3XD2eGGykdf86hOq5KkQ6jFrwUi0e8ZRJpImqRuZ46BRmY3SVFGofdR+nOSpHmY7GLFKk3UjyenUZtNtKjUvx8SXXyc5aiQINr4JPqY8jghUG77757sz2zjJmUdMc/+tGPhnkU2PDszuOPP15DgeELaTPP0GP49sQTT4QxrpnajJ7dyVZiLOySBvTpnLYm5vabvUq6oZTy41JKtxvA6FrrI5LU+TlqyEcnEokRx9x+s69fa324lDJK0o2llHvn+IgOOv857CXNfqiQSCR6h7n6Zq+1Ptz5OUPS5ZLGSXq0lLKMJHV+DioYVmudVGsdW2sd6/LOiUSid5jjN3spZRFJL6u1PtmxN5F0jKSrJO0qaWLn55VDP8ssLLDAAq1C7IEHHghjpLm8mo0a6kzDdFFJ0lwuXkgxR4pWej8t0ktnnHFGGKPwI2N2nhVIkSZidZkU40G2jpZi2i0pwXe84x1hHlM7Dz744DC2+uqrN5sCHvvvv3+YxzjaryOfkxV8XslF+s7/I2csy3MEpxFJUVEXXYpUE88RrrnmmjCPZxi+RsbRrKb0dFNeA7//SNM5tcf7mEIirg3PVF3vF8AzE1Z1HnDAAWEe05+nT58exrrpuBQlccyNGz9a0uWdTfBySV+ttV5XSrlD0jdKKbtL+q2kbYZ5jkQiMcKY42avtT4gaa1B/v6YpA1nf0QikZgX0XPxii7lQ3dciq6wu3os7n/Pe97TbApNSJFacTeHri+rvDxbio9zkQFWgNFNdRqEWWKuY8eMt1122SWMsSXyoYce2mzPNqTePOdJsdqKFA8r5aRIb1L/XYqfBSkpVm5J0T1nRaAUKSTq0FOEwp/TaTmGStTFczqTmoKefcmQjSEDXX8pUoVOpZKe9c+a1CepQ7aakmLY5K4218J5/l54wO20XJce9JbYRObGJxJ9gtzsiUSfIDd7ItEn6GnM/s9//rPFm96vi3G50zjsC0cqhZScFCuGvDqJKZWbbLJJs/184NZbb222V0Zde+21zV566aWb7a2GKcxIKkyKlXoeo/J9M5Z19RFWQ3kfOFJUfBxpMimKeLpeO983rxUrAv13/zyp+U7FFb+mjPVZVShFJRym/npbZqoXufAl06RJP3o1Is97KJYpRcqO6dpS7NNG/X0XPCUl6HE1zwF4buP3N9OT2SpaGojnPW2ZyG/2RKJPkJs9kegTFHeJXkost9xyde+995Y0e1UQxRfdLaZ+Nquf7r333iHnebtb0lWklvh8nTU2e7hcfrrxnrVFN41UihRdPR876qijmk3Ky7Xnvf0RQeEJhihOm/F6U/tcilQf3xvbJ0kxJCElKsW2TqTo3IVl1qBX35HKIlXrWYNco2cssoU19eXpfkvx+iy22GJhbKmllmo2dfn9tSkCQupRitVovueYlUfX3TXqGaYyvJIGqhonTZqkhx9+OKqMdJDf7IlEnyA3eyLRJ+jpafwzzzzTTk55sihFYQgvkmEmFTPcPIuIGWkuDMECA+p0+Yk4T4edFWAxDZ+fJ89SzPDyTD62GfL3eeGFFzabmXF+cszwgq6pFN1n6s55kQlP0l0EhCEKw63bb799yHk333xzGGOHWrrd7FgqxZNoz2qjeztt2rRms52UFDX/OM/BEIcn+JJ02223Nft973tfGKOIiYdQdPlZCHPWWWeFeQwPvc8ArzFZB8/k4/3uRVrdPgauNUjkN3si0SfIzZ5I9AlysycSfYKeUm/LLrts3WOPPSTNLqLImMb7hjHDi7HhPvvsE+ZRrMEFCFi5xCwj1/Dm9aAooxTPDtjrzXuxMYvr+uuvD2Pd9y/N3hqYz8nY1ivneK4wduzYMHbXXXc1m1SeV2GxlbFfK+qrU3veq+MYw/P5JOniiy9uNs8VGMtLUeiDWvnS0Br+3iKbzzGc0AczD/16MJ73akd+nl6JttdeezWbGYDMZPQ1e49CCmfwnvPqOFZ5epVhV6xl22231d13353UWyLRz8jNnkj0CXrqxi+11FK1KwDhmmikpNhySIpuN+kNFjn4mLfFpfDEySef3GynatgaykMNtqFi+yfXwGcWFIsopFgUQrpHipQSaUTPOqP77zrh1K5jWyTSZJK0zjrrNNuLU6jL120FPNhrsWDEs9p4jenSdjMouyDt5+2W6e6S4vL1MlvNMwV5PVhY4xluLHLyIiqGix6GsEUVKUCGMVJsM+3hCotr+N78fbKllo899dRTkqQJEybo/vvvTzc+kehn5GZPJPoEudkTiT5BT2P2pZdeuu66666SZtfOZktbb93LSiNqre+www5hHquknN6gWANjHxdAZJXUW9/61jDGSiPSMxS8kKIYpVdQMX71nl+s1ONZAgUypXiu4PQMU0xpn3jiiWEexSxIO0mRzqMABqk8KaYJO/3YjSGlSGe6yMWb3vSmZrMfmhTfGysEl1hiiTCPj3NhTVZQUvjE0035ONeG55mRi2MwlZlp2N7emqKYvud4P/KzZuWjFFN1eX4kSbfcckv7+fjjj2fMnkj0M3KzJxJ9gp5WvUkDVTmkyaToEjIrSYp01YQJE5rtwhMULthzzz3D2MteNvD/GrP1vC0zqZsNN4w9MFghR0qHWVpSDFGonyfF1slOyzFrjpVtTifR9XX3nM9J0QWvjuMa3eWk2ARDKrailiJdynbCkrTjjjs2+8tf/nKzPeuRLrPTYcwcZJaZV0yyioyCGlKk9lhVSC17KYZefF+StO+++zabAhJSzJpjxdkhhxwS5tH99/d57LHHNpthH3sM+HOccsopYawblngFJjFX3+yllFeXUi4tpdxbSvllKeWtpZQlSik3llKmdX4uPudnSiQSI4W5deNPk3RdrfX1mtUK6peSDpc0pdY6RtKUzu+JRGIexdx0cV1M0jsk7SZJtdZ/SfpXKWULSRt0pk2WdLOkw2Z/hgEsvPDCzf11+WKe5robT/eZAgfHHXdcmMdCDW+L9LGPfazZFJRgZp0UXWTP5KNgBTPoPvnJT4Z5PHH35+fpsBd0sMiCemx+Gk/NOD+ZZpYbbc/yowaba+FxLhmP+++/P8xjpqAXwvC1edr8mc98JsxjOOGFQbwel1xySbM97KA2nrdnYjhEdsWFSQ488MBm+2fG03gP2RhiMevRZbEZCnhoxxCLjJKLdPD+9lCjK8VORsAxN9/sK0v6o6QvlVJ+Wkr5Yqd18+ha6yOS1Pk5argnSSQSI4u52ewvl/RmSefUWteR9Hc9B5e9lLJXKWVqKWWqlxUmEoneYW42+0OSHqq1douXL9Wszf9oKWUZSer8nDHYg2utk2qtY2utY73GN5FI9A5z05/9D6WU35VSVqu13qdZPdl/0fm3q6SJnZ9XDvM0kmbFPt2Y2+NVilJ4XETaZbfddmu2tzwmdUWBSSmKVzBm9+o4ZmN56yZmWU2ePLnZTicxXmO1kySdc845zSY9JUUqkdSka+Cvu+66ze5mJHZBHXNmJXorIdI6nk3GMYokOAXIWNZjSK6ZQp1e8cXqR29pxPibdKBnsZGKc++R14qxvVO/PINxUUnSm6TvpJgRyNf2akoKgboAxgc+8IFm88zoiiuuCPN4fVwktHutWKXomFue/aOSLi6lLCDpAUkf0iyv4BullN0l/VbSNsM8PpFIjDDmarPXWu+UNHaQoQ0H+VsikZgH0dMMuqeeeqpl+HjGFcUDqLsuxVZFFKxwF5n6a65xzoIOup8MC6Soze0FEXT/ma3nhTts2+PZUizGcIqHbjy11HhtpEjtebdQ6tiRsvT3SarJM+OYOci2WS4WcuSRRzbbqSZSgixCcj1/FhF5YRDbKVF/zbX4KUrhGnQMlRjaTZ06Ncy76KKLmu369QwXGRb487CtGENPKd6P3jmY15/h4bhx48I8Znt6+6qucMZwbnzmxicSfYLc7IlEnyA3eyLRJ+ipeMXo0aNrN1b3tsyMcbwXFtMLGbu5ECNjyJ122imMHXDAAc1mbO90EmNNj/sZDzGF1dsVM+ZzgUKm8W677bZDjjHt0eOz3/3ud812TXmKavBsgpSOJF166aWDPkaKFCZ7j/F1pRhTO6W29dZbN5t9zyiCKcUYnq8lDd2aupsa2gXTSr2lMp+DKdMU75Ai3ehpu9TOd5p19913bzZTvj0dnOm+Th0SvI4UKZGimIW/z27K83HHHafp06eneEUi0c/IzZ5I9Al66saXUv4o6TeSlpT0pzlM7wVyHRG5joh5YR3PdQ0r1lqXGmygp5u9vWgpU2utgyXp5DpyHbmOl2gN6cYnEn2C3OyJRJ9gpDb7pDlP6QlyHRG5joh5YR0v2hpGJGZPJBK9R7rxiUSfoKebvZQyvpRyXynl16WUnqnRllIuKKXMKKXcjb/1XAq7lPLaUspNHTnue0opB47EWkopC5VSflRKuauzjqNHYh1Yz3wdfcOrR2odpZTppZSfl1LuLKVMHcF1vGSy7T3b7KWU+SSdJek9ktaQtH0pZY3hH/Wi4cuSxtvfRkIK+xlJh9RaV5e0nqT9Oteg12t5WtK7aq1rSVpb0vhSynojsI4uDtQsefIuRmod76y1rg2qayTW8dLJttdae/JP0lslXY/fJ0ia0MPXX0nS3fj9PknLdOxlJN3Xq7VgDVdK2ngk1yLpFZJ+IuktI7EOSct3buB3Sbp6pD4bSdMlLWl/6+k6JC0m6UF1ztJe7HX00o1fThIrKR7q/G2kMKJS2KWUlSStI+n2kVhLx3W+U7OEQm+sswRFR+KanCrpUElsRzsS66iSbiil/LiU0m1c0Ot1vKSy7b3c7INV4vQlFVBKWVTSZZIOqrX+dSTWUGudWWtdW7O+WceVUtacw0NedJRSNpc0o9b64zlOfumxfq31zZoVZu5XSnnHnB7wEuAFybbPCb3c7A9JYs3i8pIeHmJuLzBXUtgvNkop82vWRr+41tqt3R2RtUhSrfVxzermM34E1rG+pPeVUqZLukTSu0opF43AOlRrfbjzc4akyyWNG4F1vCDZ9jmhl5v9DkljSimv66jUbifpqjk85qXEVZolgS3NpRT2C0WZ1bfofEm/rLWyDWdP11JKWaqU8uqOvbCkjSTd2+t11Fon1FqXr7WupFn3w3drrTv1eh2llEVKKa/s2pI2kXR3r9dRa/2DpN+VUrpCgl3Z9hdnHS/1wYcdNGwq6VeS7pd0ZA9f92uSHpH0b83633N3Sa/RrIOhaZ2fS/RgHf+lWaHLzyTd2fm3aa/XIulNkn7aWcfdkj7V+XvPrwnWtIEGDuh6fT1WlnRX59893XtzhO6RtSVN7Xw2V0ha/MVaR2bQJRJ9gsygSyT6BLnZE4k+QW72RKJPkJs9kegT5GZPJPoEudkTiT5BbvZEok+Qmz2R6BP8P3i3yZnE04j+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 動作確認\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = Generator(z_dim=20, image_size=64)\n",
    "\n",
    "# 入力する乱数\n",
    "input_z = torch.randn(1, 20)\n",
    "\n",
    "# テンソルサイズを(1, 20, 1, 1)に変形\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "\n",
    "# 偽画像を出力\n",
    "fake_images = G(input_z)\n",
    "\n",
    "img_transformed = fake_images[0][0].detach().numpy()\n",
    "plt.imshow(img_transformed, 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jboyUE0NTRU"
   },
   "source": [
    "# Discriminatorの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dis_lyr:\n",
    "    def input_lyr(z_dim, image_size):\n",
    "        lyr = nn.Sequential(\n",
    "            nn.Conv2d(1, image_size, kernel_size=4,\n",
    "                     stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        return lyr\n",
    "    \n",
    "    def hdn_lyr(image_size, i):\n",
    "        lyr = nn.Sequential(\n",
    "            nn.Conv2d(image_size * (2 ** i),\n",
    "                      image_size * (2 ** (i+1)),\n",
    "                      kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        return lyr\n",
    "    \n",
    "    def output_lyr(image_size):\n",
    "        lyr = nn.Sequential(\n",
    "            nn.Conv2d(image_size ** 2 // 8, 1,\n",
    "                      kernel_size=4, stride=1))\n",
    "        return lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, z_dim=20, image_size=64):\n",
    "        super().__init__()\n",
    "        self.input_lyr = dis_lyr.input_lyr(z_dim, image_size)\n",
    "        self.hdn_lyr0 = dis_lyr.hdn_lyr(image_size, 0)\n",
    "        self.hdn_lyr1 = dis_lyr.hdn_lyr(image_size, 1)\n",
    "        self.hdn_lyr2 = dis_lyr.hdn_lyr(image_size, 2)\n",
    "        self.output_lyr = dis_lyr.output_lyr(image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.input_lyr(x)\n",
    "        out = self.hdn_lyr0(out)\n",
    "        out = self.hdn_lyr1(out)\n",
    "        out = self.hdn_lyr2(out)\n",
    "\n",
    "        feature = out  # 最後にチャネルを1つに集約する手前の情報\n",
    "        feature = feature.view(feature.size()[0], -1)  # 2次元に変換\n",
    "\n",
    "        out = self.output_lyr(out)\n",
    "\n",
    "        return out, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3revWoTwNTRX",
    "outputId": "74eecd6a-5227-4d3c-8267-2fa0468be600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5066]]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([1, 8192])\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "D = Discriminator(z_dim=20, image_size=64)\n",
    "\n",
    "# 偽画像を生成\n",
    "input_z = torch.randn(1, 20)\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "fake_images = G(input_z)\n",
    "\n",
    "# 偽画像をDに入力\n",
    "d_out = D(fake_images)\n",
    "\n",
    "# 出力d_outにSigmoidをかけて0から1に変換\n",
    "print(nn.Sigmoid()(d_out[0]))\n",
    "\n",
    "# feature\n",
    "print(d_out[1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QAME7J8vNTRa"
   },
   "source": [
    "# DataLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, random\n",
    "def make_datapath_list(path, i):\n",
    "    \"\"\"学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する。 \"\"\"\n",
    "    til = glob.glob(path)\n",
    "    random.shuffle(til)\n",
    "    if i == \"a\":\n",
    "        train_img_list = til[:]\n",
    "    else:\n",
    "        train_img_list = til[:i]\n",
    "    return train_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/home/atsuk/Desktop/pytorch_advanced/6_gan_anomaly_detection\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/home/atsuk/Desktop/abnormal_detection_data/train/020850.tif',\n",
       " '/mnt/home/atsuk/Desktop/abnormal_detection_data/train/020019.tif',\n",
       " '/mnt/home/atsuk/Desktop/abnormal_detection_data/train/012678.tif',\n",
       " '/mnt/home/atsuk/Desktop/abnormal_detection_data/train/028440.tif',\n",
       " '/mnt/home/atsuk/Desktop/abnormal_detection_data/train/021590.tif']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = '/media/tamahassam/Extreme SSD/normal_ct_visual/*.tif'\n",
    "# path = '/home/ubuntu/normal_ct_visual/*.tif'\n",
    "path = '/mnt/home/atsuk/Desktop/abnormal_detection_data/train/*.tif'\n",
    "l = make_datapath_list(path, 5)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1npqlImNTRd"
   },
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \"\"\"画像の前処理クラス\"\"\"\n",
    "\n",
    "    def __init__(self, resize):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize(mean, std)\n",
    "        ])\n",
    "        self.resize = resize\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \n",
    "        return F.adaptive_avg_pool2d(self.data_transform(np.array(img)), (self.resize, self.resize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUPqAsOINTRg"
   },
   "outputs": [],
   "source": [
    "class GAN_Img_Dataset(data.Dataset):\n",
    "    \"\"\"画像のDatasetクラス。PyTorchのDatasetクラスを継承\"\"\"\n",
    "\n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''画像の枚数を返す'''\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''前処理をした画像のTensor形式のデータを取得'''\n",
    "\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)  # [高さ][幅]白黒\n",
    "\n",
    "        # 画像の前処理\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        return img_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFt0gdYpNTRi",
    "outputId": "2b8ad2cf-915e-4ea0-fff3-03328102ba4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# DataLoaderの作成と動作確認\n",
    "\n",
    "# ファイルリストを作成\n",
    "num_of_data = \"a\"\n",
    "# path = '/media/tamahassam/Extreme SSD/normal_ct_visual/*.tif'\n",
    "path = '/mnt/home/atsuk/Desktop/abnormal_detection_data/train/*.tif'\n",
    "train_img_list=make_datapath_list(path, num_of_data)\n",
    "\n",
    "# Datasetを作成\n",
    "resize = 64\n",
    "# mean = (0.5,)\n",
    "# std = (0.5,)\n",
    "train_dataset = GAN_Img_Dataset(\n",
    "    file_list=train_img_list, transform=ImageTransform(resize))\n",
    "\n",
    "# DataLoaderを作成\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 動作の確認\n",
    "batch_iterator = iter(train_dataloader)  # イテレータに変換\n",
    "imges = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "print(imges.size())  # torch.Size([64, 1, 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yCBgnXKjNTRl"
   },
   "source": [
    "# 学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHFCLZtnNTRm",
    "outputId": "4e13cfe8-98a1-4a70-e580-ac2d7338cb63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワークの初期化完了\n"
     ]
    }
   ],
   "source": [
    "# ネットワークの初期化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        # Conv2dとConvTranspose2dの初期化\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        # BatchNorm2dの初期化\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# 初期化の実施\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "print(\"ネットワークの初期化完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYKH3_EyNTRo"
   },
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "\n",
    "def train_model(G, D, dataloader, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "\n",
    "    # 最適化手法の設定\n",
    "    g_lr, d_lr = 0.0001, 0.0004\n",
    "    beta1, beta2 = 0.0, 0.9\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), g_lr, [beta1, beta2])\n",
    "    d_optimizer = torch.optim.Adam(D.parameters(), d_lr, [beta1, beta2])\n",
    "\n",
    "    # 誤差関数を定義\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "    # パラメータをハードコーディング\n",
    "    z_dim = 20\n",
    "    mini_batch_size = 64\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    G.to(device)\n",
    "    D.to(device)\n",
    "\n",
    "    G.train()  # モデルを訓練モードに\n",
    "    D.train()  # モデルを訓練モードに\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 画像の枚数\n",
    "    num_train_imgs = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        epoch_g_loss = 0.0  # epochの損失和\n",
    "        epoch_d_loss = 0.0  # epochの損失和\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-------------')\n",
    "        print('（train）')\n",
    "\n",
    "        # データローダーからminibatchずつ取り出すループ\n",
    "        for imges in dataloader:\n",
    "\n",
    "            # --------------------\n",
    "            # 1. Discriminatorの学習\n",
    "            # --------------------\n",
    "            # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
    "            if imges.size()[0] == 1:\n",
    "                continue\n",
    "\n",
    "            # GPUが使えるならGPUにデータを送る\n",
    "            imges = imges.to(device)\n",
    "\n",
    "            # 正解ラベルと偽ラベルを作成\n",
    "            # epochの最後のイテレーションはミニバッチの数が少なくなる\n",
    "            mini_batch_size = imges.size()[0]\n",
    "            label_real = torch.full((mini_batch_size,), 1).to(device)\n",
    "            label_fake = torch.full((mini_batch_size,), 0).to(device)\n",
    "\n",
    "            # 真の画像を判定\n",
    "            d_out_real, _ = D(imges)\n",
    "\n",
    "            # 偽の画像を生成して判定\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake, _ = D(fake_images)\n",
    "\n",
    "\n",
    "            # 誤差を計算\n",
    "            label_real = label_real.type_as(d_out_real.view(-1))\n",
    "            d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
    "            label_fake = label_fake.type_as(d_out_fake.view(-1))\n",
    "            d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 2. Generatorの学習\n",
    "            # --------------------\n",
    "            # 偽の画像を生成して判定\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake, _ = D(fake_images)\n",
    "\n",
    "            # 誤差を計算\n",
    "            g_loss = criterion(d_out_fake.view(-1), label_real)\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 3. 記録\n",
    "            # --------------------\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            iteration += 1\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f}'.format(\n",
    "            epoch, epoch_d_loss/batch_size, epoch_g_loss/batch_size))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "    \n",
    "    print(\"総イテレーション回数:\", iteration)\n",
    "\n",
    "    return G, D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eA_fJqfqNTRq",
    "outputId": "fd9451a5-3361-401d-9ad3-65f4f3cf04fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cuda:0\n",
      "-------------\n",
      "Epoch 0/15\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 0 || Epoch_D_Loss:5.8759 ||Epoch_G_Loss:26.0213\n",
      "timer:  85.8707 sec.\n",
      "-------------\n",
      "Epoch 1/15\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 1 || Epoch_D_Loss:2.9186 ||Epoch_G_Loss:43.2433\n",
      "timer:  88.5683 sec.\n",
      "-------------\n",
      "Epoch 2/15\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 2 || Epoch_D_Loss:2.3273 ||Epoch_G_Loss:48.6596\n",
      "timer:  88.6934 sec.\n",
      "-------------\n",
      "Epoch 3/15\n",
      "-------------\n",
      "（train）\n"
     ]
    }
   ],
   "source": [
    "# 学習・検証を実行する\n",
    "# 2分/epochほどかかる\n",
    "num_epochs = 15\n",
    "G_update, D_update = train_model(\n",
    "    G, D, dataloader=train_dataloader, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fmp51OyNTRs",
    "outputId": "948838ac-4fe1-445c-f306-01003a2e88d6"
   },
   "outputs": [],
   "source": [
    "# 生成画像と訓練データを可視化する\n",
    "# 本セルは何度か実行し直しています。\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 入力の乱数生成\n",
    "batch_size = 8\n",
    "z_dim = 20\n",
    "fixed_z = torch.randn(batch_size, z_dim)\n",
    "fixed_z = fixed_z.view(fixed_z.size(0), fixed_z.size(1), 1, 1)\n",
    "fake_images = G_update(fixed_z.to(device))\n",
    "\n",
    "# 訓練データ\n",
    "batch_iterator = iter(train_dataloader)  # イテレータに変換\n",
    "imges = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "\n",
    "\n",
    "# 出力\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 上段に訓練データを\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 下段に生成データを表示する\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONi7hdK2NTRv"
   },
   "source": [
    "# AnoGANの本体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-P7OJnwNTRw"
   },
   "outputs": [],
   "source": [
    "def Anomaly_score(x, fake_img, D, Lambda=0.1):\n",
    "\n",
    "    # テスト画像xと生成画像fake_imgのピクセルレベルの差の絶対値を求めて、ミニバッチごとに和を求める\n",
    "    residual_loss = torch.abs(x-fake_img)\n",
    "    residual_loss = residual_loss.view(residual_loss.size()[0], -1)\n",
    "    residual_loss = torch.sum(residual_loss, dim=1)\n",
    "\n",
    "    # テスト画像xと生成画像fake_imgを識別器Dに入力し、特徴量を取り出す\n",
    "    _, x_feature = D(x)\n",
    "    _, G_feature = D(fake_img)\n",
    "\n",
    "    # テスト画像xと生成画像fake_imgの特徴量の差の絶対値を求めて、ミニバッチごとに和を求める\n",
    "    discrimination_loss = torch.abs(x_feature-G_feature)\n",
    "    discrimination_loss = discrimination_loss.view(\n",
    "        discrimination_loss.size()[0], -1)\n",
    "    discrimination_loss = torch.sum(discrimination_loss, dim=1)\n",
    "\n",
    "    # ミニバッチごとに2種類の損失を足し算する\n",
    "    loss_each = (1-Lambda)*residual_loss + Lambda*discrimination_loss\n",
    "\n",
    "    # ミニバッチ全部の損失を求める\n",
    "    total_loss = torch.sum(loss_each)\n",
    "\n",
    "    return total_loss, loss_each, residual_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6znyqRZzNTRy"
   },
   "source": [
    "# covid画像で異常検知する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abn_path = '/mnt/home/atsuk/Desktop/abnormal_detection_data/covid/*.tif'\n",
    "abn_list = make_datapath_list(abn_path, 5)\n",
    "abn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im_abn = Image.open(abn_list[0])\n",
    "im_abn = np.array(im_abn)\n",
    "print(f'size :{im_abn.shape}')\n",
    "plt.imshow(im_abn, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiStymFxNTRy"
   },
   "outputs": [],
   "source": [
    "# 異常のDataLoaderの作成\n",
    "\n",
    "# Datasetを作成\n",
    "# mean = (0.5,)\n",
    "# std = (0.5,)\n",
    "test_dataset = GAN_Img_Dataset(\n",
    "    file_list= abn_list, transform=ImageTransform(resize))\n",
    "\n",
    "# DataLoaderを作成\n",
    "batch_size = 5\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuyHrvz5NTR0",
    "outputId": "3382f9fb-1013-465f-81cf-218e39a5289e"
   },
   "outputs": [],
   "source": [
    "# テストデータの確認\n",
    "batch_iterator = iter(test_dataloader)  # イテレータに変換\n",
    "imges = next(batch_iterator)  \n",
    "\n",
    "# 1番目のミニバッチを取り出す\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'min: {imges[0].min()}')\n",
    "print(f'max: {imges[0].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOAa2MlYNTR3",
    "outputId": "27bafb1e-3f2e-4bd6-cedd-6c08b2a8e23a"
   },
   "outputs": [],
   "source": [
    "# 異常検知したい画像\n",
    "x = imges[0:5]\n",
    "x = x.to(device)\n",
    "\n",
    "# 異常検知したい画像を生成するための、初期乱数\n",
    "z = torch.randn(5, 20).to(device)\n",
    "z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "\n",
    "# 変数zを微分を求めることが可能なように、requires_gradをTrueに設定\n",
    "z.requires_grad = True\n",
    "\n",
    "# 変数zを更新できるように、zの最適化関数を求める\n",
    "z_optimizer = torch.optim.Adam([z], lr=1e-3)\n",
    "\n",
    "\n",
    "# zを求める\n",
    "for epoch in range(5000+1):\n",
    "    fake_img = G_update(z)\n",
    "    loss, _, _ = Anomaly_score(x, fake_img, D_update, Lambda=0.1)\n",
    "\n",
    "    z_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    z_optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print('epoch {} || loss_total:{:.0f} '.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fofex37oNTR5",
    "outputId": "320b5428-ed6d-42d0-e308-92f1dce6669f"
   },
   "outputs": [],
   "source": [
    "# 画像を生成\n",
    "G_update.eval()\n",
    "fake_img = G_update(z)\n",
    "\n",
    "# 損失を求める\n",
    "loss, loss_each, residual_loss_each = Anomaly_score(\n",
    "    x, fake_img, D_update, Lambda=0.1)\n",
    "\n",
    "# 損失の計算。トータルの損失\n",
    "loss_each = loss_each.cpu().detach().numpy()\n",
    "print(\"total loss：\", np.round(loss_each, 0))\n",
    "\n",
    "# 画像を可視化\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 上段にテストデータを\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 下段に生成データを表示する\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    plt.imshow(fake_img[i][0].cpu().detach().numpy(), 'gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正常画像で異常検知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_path = '/mnt/home/atsuk/Desktop/abnormal_detection_data/normal/*.tif'\n",
    "normal_list = make_datapath_list(normal_path, 5)\n",
    "normal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異常のDataLoaderの作成\n",
    "\n",
    "# Datasetを作成\n",
    "# mean = (0.5,)\n",
    "# std = (0.5,)\n",
    "test_dataset = GAN_Img_Dataset(\n",
    "    file_list= abn_list, transform=ImageTransform(resize))\n",
    "\n",
    "# DataLoaderを作成\n",
    "batch_size = 5\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの確認\n",
    "batch_iterator = iter(test_dataloader)  # イテレータに変換\n",
    "imges = next(batch_iterator)  \n",
    "\n",
    "# 1番目のミニバッチを取り出す\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOAa2MlYNTR3",
    "outputId": "27bafb1e-3f2e-4bd6-cedd-6c08b2a8e23a"
   },
   "outputs": [],
   "source": [
    "# 異常検知したい画像\n",
    "x = imges[0:5]\n",
    "x = x.to(device)\n",
    "\n",
    "# 異常検知したい画像を生成するための、初期乱数\n",
    "z = torch.randn(5, 20).to(device)\n",
    "z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "\n",
    "# 変数zを微分を求めることが可能なように、requires_gradをTrueに設定\n",
    "z.requires_grad = True\n",
    "\n",
    "# 変数zを更新できるように、zの最適化関数を求める\n",
    "z_optimizer = torch.optim.Adam([z], lr=1e-3)\n",
    "\n",
    "\n",
    "# zを求める\n",
    "for epoch in range(5000+1):\n",
    "    fake_img = G_update(z)\n",
    "    loss, _, _ = Anomaly_score(x, fake_img, D_update, Lambda=0.1)\n",
    "\n",
    "    z_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    z_optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print('epoch {} || loss_total:{:.0f} '.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fofex37oNTR5",
    "outputId": "320b5428-ed6d-42d0-e308-92f1dce6669f"
   },
   "outputs": [],
   "source": [
    "# 画像を生成\n",
    "G_update.eval()\n",
    "fake_img = G_update(z)\n",
    "\n",
    "# 損失を求める\n",
    "loss, loss_each, residual_loss_each = Anomaly_score(\n",
    "    x, fake_img, D_update, Lambda=0.1)\n",
    "\n",
    "# 損失の計算。トータルの損失\n",
    "loss_each = loss_each.cpu().detach().numpy()\n",
    "print(\"total loss：\", np.round(loss_each, 0))\n",
    "\n",
    "# 画像を可視化\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 上段にテストデータを\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 下段に生成データを表示する\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    plt.imshow(fake_img[i][0].cpu().detach().numpy(), 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みを保存\n",
    "G_save_path = \"/mnt/home/atsuk/Desktop/pytorch_advanced/6_gan_anomaly_detection/G_ano_dc_64_20_15ep.pth\"\n",
    "D_save_path = \"/mnt/home/atsuk/Desktop/pytorch_advanced/6_gan_anomaly_detection/D_ano_dc_64_20_15ep.pth\"\n",
    "torch.save(G.state_dict(), G_save_path)\n",
    "torch.save(D.state_dict(), D_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8v2SE8_6NTR6"
   },
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6-2_AnoGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
