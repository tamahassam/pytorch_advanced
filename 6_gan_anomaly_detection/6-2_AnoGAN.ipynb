{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3SuZ-jXhNTRE"
   },
   "source": [
    "# 6.2 AnoGANの作成\n",
    "\n",
    "- 本ファイルでは、AnoGANのネットワークを実装とAnoGANの学習をします。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGPAU-EpNTRF"
   },
   "source": [
    "# 6.2 学習目標\n",
    "\n",
    "1.\tAnoGANでテスト画像に最も似た画像を生成するノイズzを求める方法を理解する\n",
    "2.\tAnoGANを実装し、手書き数字画像で異常検知が生成できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cJuKeVRNTRF"
   },
   "source": [
    "# 事前準備\n",
    "書籍の指示に従い、本章で使用するデータを用意します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3LCPGrVNTRG"
   },
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUnJkIgSNTRJ"
   },
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZygEkOn_NTRM"
   },
   "source": [
    "# Generatorの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_iptlyr(image_size, i):\n",
    "    lyr = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, image_size * 2 ** i, \n",
    "                               kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(image_size * 2 ** i),\n",
    "            nn.ReLU(inplace=True))\n",
    "    return lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_hdnlyr(image_size, i):\n",
    "    lyr = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 2 ** i, image_size * 2 ** i,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size),\n",
    "            nn.ReLU(inplace=True))\n",
    "    return lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWBi040tNTRP"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim, image_size=256):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, image_size * 32,\n",
    "                               kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(image_size * 32),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 32, image_size * 16,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * 16),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 16, image_size * 8,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * 8),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 8, image_size * 4,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * 4),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 4, image_size * 2,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * 2),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 2, image_size,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size, 1, kernel_size=4,\n",
    "                               stride=2, padding=1),\n",
    "            nn.Tanh())\n",
    "        # 注意：白黒画像なので出力チャネルは1つだけ\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.layer1(z)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WyU7Yx0KNTRS",
    "outputId": "2c3e3f01-79fb-467c-b6f8-481ca9038741"
   },
   "outputs": [],
   "source": [
    "# 動作確認\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "z_dim = 50\n",
    "\n",
    "G = Generator(z_dim=z_dim, image_size=256)\n",
    "\n",
    "# 入力する乱数\n",
    "input_z = torch.randn(1, z_dim)\n",
    "\n",
    "# テンソルサイズを(1, 20, 1, 1)に変形\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "\n",
    "# 偽画像を出力\n",
    "fake_images = G(input_z)\n",
    "\n",
    "img_transformed = fake_images[0][0].detach().numpy()\n",
    "plt.imshow(img_transformed, 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jboyUE0NTRU"
   },
   "source": [
    "# Discriminatorの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LOT-a3YNTRV"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim, image_size=256):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, image_size, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        # 注意：白黒画像なので入力チャネルは1つだけ\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(image_size, image_size*2, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*2, image_size*4, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*4, image_size*8, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*8, image_size*16, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*16, image_size*32, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.last = nn.Conv2d(image_size*32, 1, kernel_size=4, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "\n",
    "\n",
    "        feature = out  # 最後にチャネルを1つに集約する手前の情報\n",
    "        feature = feature.view(feature.size()[0], -1)  # 2次元に変換\n",
    "\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out, feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3revWoTwNTRX",
    "outputId": "74eecd6a-5227-4d3c-8267-2fa0468be600"
   },
   "outputs": [],
   "source": [
    "# 動作確認\n",
    "z_dim = 50\n",
    "D = Discriminator(z_dim=z_dim, image_size=256)\n",
    "\n",
    "# 偽画像を生成\n",
    "input_z = torch.randn(1, z_dim)\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "fake_images = G(input_z)\n",
    "\n",
    "# 偽画像をDに入力\n",
    "d_out = D(fake_images)\n",
    "\n",
    "# 出力d_outにSigmoidをかけて0から1に変換\n",
    "print(nn.Sigmoid()(d_out[0]))\n",
    "\n",
    "# feature\n",
    "print(d_out[1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QAME7J8vNTRa"
   },
   "source": [
    "# DataLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WpqJLFRNTRb"
   },
   "outputs": [],
   "source": [
    "import glob, random\n",
    "def make_datapath_list(i):\n",
    "    \"\"\"学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する。 \"\"\"\n",
    "    # path = '/media/tamahassam/Extreme SSD/normal_ct_visual/*.tif'\n",
    "    path = '/data/images/media/tamahassam/Extreme SSD/normal_ct_visual/*.tif'\n",
    "    til = glob.glob(path)\n",
    "    random.shuffle(til)\n",
    "    train_img_list = til[:i]\n",
    "    return train_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/images/media/tamahassam/Extreme SSD/normal_ct_visual/041763.tif',\n",
       " '/data/images/media/tamahassam/Extreme SSD/normal_ct_visual/013329.tif',\n",
       " '/data/images/media/tamahassam/Extreme SSD/normal_ct_visual/021182.tif',\n",
       " '/data/images/media/tamahassam/Extreme SSD/normal_ct_visual/032614.tif',\n",
       " '/data/images/media/tamahassam/Extreme SSD/normal_ct_visual/003323.tif']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = make_datapath_list(36000)\n",
    "l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1npqlImNTRd"
   },
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \"\"\"画像の前処理クラス\"\"\"\n",
    "\n",
    "    def __init__(self, resize):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize(mean, std)\n",
    "        ])\n",
    "        self.resize = resize\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \n",
    "        return F.adaptive_avg_pool2d(self.data_transform(np.array(img)), (self.resize, self.resize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUPqAsOINTRg"
   },
   "outputs": [],
   "source": [
    "class GAN_Img_Dataset(data.Dataset):\n",
    "    \"\"\"画像のDatasetクラス。PyTorchのDatasetクラスを継承\"\"\"\n",
    "\n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''画像の枚数を返す'''\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''前処理をした画像のTensor形式のデータを取得'''\n",
    "\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)  # [高さ][幅]白黒\n",
    "\n",
    "        # 画像の前処理\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        return img_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFt0gdYpNTRi",
    "outputId": "2b8ad2cf-915e-4ea0-fff3-03328102ba4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# DataLoaderの作成と動作確認\n",
    "\n",
    "# ファイルリストを作成\n",
    "num_of_data = 36000\n",
    "train_img_list=make_datapath_list(num_of_data)\n",
    "\n",
    "# Datasetを作成\n",
    "resize = 256\n",
    "# mean = (0.5,)\n",
    "# std = (0.5,)\n",
    "train_dataset = GAN_Img_Dataset(\n",
    "    file_list=train_img_list, transform=ImageTransform(resize))\n",
    "\n",
    "# DataLoaderを作成\n",
    "batch_size = 2\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 動作の確認\n",
    "batch_iterator = iter(train_dataloader)  # イテレータに変換\n",
    "imges = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "print(imges.size())  # torch.Size([64, 1, 64, 64])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yCBgnXKjNTRl"
   },
   "source": [
    "# 学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHFCLZtnNTRm",
    "outputId": "4e13cfe8-98a1-4a70-e580-ac2d7338cb63"
   },
   "outputs": [],
   "source": [
    "# ネットワークの初期化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        # Conv2dとConvTranspose2dの初期化\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        # BatchNorm2dの初期化\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# 初期化の実施\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "print(\"ネットワークの初期化完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYKH3_EyNTRo"
   },
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "def train_model(G, D, dataloader, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "\n",
    "    # 最適化手法の設定\n",
    "    g_lr, d_lr = 0.0001, 0.0004\n",
    "    beta1, beta2 = 0.0, 0.9\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), g_lr, [beta1, beta2])\n",
    "    d_optimizer = torch.optim.Adam(D.parameters(), d_lr, [beta1, beta2])\n",
    "\n",
    "    # 誤差関数を定義\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "    # パラメータをハードコーディング\n",
    "    z_dim = 50\n",
    "    mini_batch_size = 2\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    G.to(device)\n",
    "    D.to(device)\n",
    "\n",
    "    G.train()  # モデルを訓練モードに\n",
    "    D.train()  # モデルを訓練モードに\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 画像の枚数\n",
    "    num_train_imgs = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        epoch_g_loss = 0.0  # epochの損失和\n",
    "        epoch_d_loss = 0.0  # epochの損失和\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-------------')\n",
    "        print('（train）')\n",
    "\n",
    "        # データローダーからminibatchずつ取り出すループ\n",
    "        for imges in dataloader:\n",
    "\n",
    "            # --------------------\n",
    "            # 1. Discriminatorの学習\n",
    "            # --------------------\n",
    "            # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
    "            if imges.size()[0] == 1:\n",
    "                continue\n",
    "\n",
    "            # GPUが使えるならGPUにデータを送る\n",
    "            imges = imges.to(device)\n",
    "\n",
    "            # 正解ラベルと偽ラベルを作成\n",
    "            # epochの最後のイテレーションはミニバッチの数が少なくなる\n",
    "            mini_batch_size = imges.size()[0]\n",
    "            label_real = torch.full((mini_batch_size,), 1).to(device)\n",
    "            label_fake = torch.full((mini_batch_size,), 0).to(device)\n",
    "\n",
    "            # 真の画像を判定\n",
    "            d_out_real, _ = D(imges)\n",
    "\n",
    "            # 偽の画像を生成して判定\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake, _ = D(fake_images)\n",
    "\n",
    "            # 誤差を計算\n",
    "            label_real = label_real.type_as(d_out_real.view(-1))\n",
    "            label_fake = label_fake.type_as(d_out_fake.view(-1))\n",
    "            d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
    "            d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            \n",
    "             # 誤差を計算\n",
    "        \n",
    "            # バックプロパゲーション\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 2. Generatorの学習\n",
    "            # --------------------\n",
    "            # 偽の画像を生成して判定\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake, _ = D(fake_images)\n",
    "\n",
    "            # 誤差を計算\n",
    "            g_loss = criterion(d_out_fake.view(-1), label_real)\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 3. 記録\n",
    "            # --------------------\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            iteration += 1\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f}'.format(\n",
    "            epoch, epoch_d_loss/batch_size, epoch_g_loss/batch_size))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "    \n",
    "    print(\"総イテレーション回数:\", iteration)\n",
    "\n",
    "    return G, D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 14 10:01:59 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   38C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eA_fJqfqNTRq",
    "outputId": "fd9451a5-3361-401d-9ad3-65f4f3cf04fb"
   },
   "outputs": [],
   "source": [
    "# 学習・検証を実行する\n",
    "# 8分ほどかかる\n",
    "num_epochs = 10\n",
    "z_dim = 50\n",
    "G = Generator(z_dim=z_dim, image_size=256)\n",
    "D = Discriminator(z_dim=z_dim, image_size=256)\n",
    "\n",
    "G_update, D_update = train_model(\n",
    "    G, D, dataloader=train_dataloader, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fmp51OyNTRs",
    "outputId": "948838ac-4fe1-445c-f306-01003a2e88d6"
   },
   "outputs": [],
   "source": [
    "# 生成画像と訓練データを可視化する\n",
    "# 本セルは何度か実行し直しています。\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 入力の乱数生成\n",
    "batch_size = 8\n",
    "z_dim = 20\n",
    "fixed_z = torch.randn(batch_size, z_dim)\n",
    "fixed_z = fixed_z.view(fixed_z.size(0), fixed_z.size(1), 1, 1)\n",
    "fake_images = G_update(fixed_z.to(device))\n",
    "\n",
    "# 訓練データ\n",
    "batch_iterator = iter(train_dataloader)  # イテレータに変換\n",
    "imges = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "\n",
    "\n",
    "# 出力\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 上段に訓練データを\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 下段に生成データを表示する\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONi7hdK2NTRv"
   },
   "source": [
    "# AnoGANの本体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-P7OJnwNTRw"
   },
   "outputs": [],
   "source": [
    "def Anomaly_score(x, fake_img, D, Lambda=0.1):\n",
    "\n",
    "    # テスト画像xと生成画像fake_imgのピクセルレベルの差の絶対値を求めて、ミニバッチごとに和を求める\n",
    "    residual_loss = torch.abs(x-fake_img)\n",
    "    residual_loss = residual_loss.view(residual_loss.size()[0], -1)\n",
    "    residual_loss = torch.sum(residual_loss, dim=1)\n",
    "\n",
    "    # テスト画像xと生成画像fake_imgを識別器Dに入力し、特徴量を取り出す\n",
    "    _, x_feature = D(x)\n",
    "    _, G_feature = D(fake_img)\n",
    "\n",
    "    # テスト画像xと生成画像fake_imgの特徴量の差の絶対値を求めて、ミニバッチごとに和を求める\n",
    "    discrimination_loss = torch.abs(x_feature-G_feature)\n",
    "    discrimination_loss = discrimination_loss.view(\n",
    "        discrimination_loss.size()[0], -1)\n",
    "    discrimination_loss = torch.sum(discrimination_loss, dim=1)\n",
    "\n",
    "    # ミニバッチごとに2種類の損失を足し算する\n",
    "    loss_each = (1-Lambda)*residual_loss + Lambda*discrimination_loss\n",
    "\n",
    "    # ミニバッチ全部の損失を求める\n",
    "    total_loss = torch.sum(loss_each)\n",
    "\n",
    "    return total_loss, loss_each, residual_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6znyqRZzNTRy"
   },
   "source": [
    "# テスト画像で異常検知する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiStymFxNTRy"
   },
   "outputs": [],
   "source": [
    "# テスト用のDataLoaderの作成\n",
    "\n",
    "\n",
    "def make_test_datapath_list():\n",
    "    \"\"\"学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する。 \"\"\"\n",
    "\n",
    "    train_img_list = list()  # 画像ファイルパスを格納\n",
    "\n",
    "    for img_idx in range(5):\n",
    "        img_path = \"./data/test/img_7_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "        img_path = \"./data/test/img_8_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "        img_path = \"./data/test/img_2_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "    return train_img_list\n",
    "\n",
    "\n",
    "# ファイルリストを作成\n",
    "test_img_list = make_test_datapath_list()\n",
    "\n",
    "# Datasetを作成\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "test_dataset = GAN_Img_Dataset(\n",
    "    file_list=test_img_list, transform=ImageTransform(mean, std))\n",
    "\n",
    "# DataLoaderを作成\n",
    "batch_size = 5\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuyHrvz5NTR0",
    "outputId": "3382f9fb-1013-465f-81cf-218e39a5289e"
   },
   "outputs": [],
   "source": [
    "# テストデータの確認\n",
    "batch_iterator = iter(test_dataloader)  # イテレータに変換\n",
    "imges = next(batch_iterator)  \n",
    "\n",
    "# 1番目のミニバッチを取り出す\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOAa2MlYNTR3",
    "outputId": "27bafb1e-3f2e-4bd6-cedd-6c08b2a8e23a"
   },
   "outputs": [],
   "source": [
    "# 異常検知したい画像\n",
    "x = imges[0:5]\n",
    "x = x.to(device)\n",
    "\n",
    "# 異常検知したい画像を生成するための、初期乱数\n",
    "z = torch.randn(5, 20).to(device)\n",
    "z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "\n",
    "# 変数zを微分を求めることが可能なように、requires_gradをTrueに設定\n",
    "z.requires_grad = True\n",
    "\n",
    "# 変数zを更新できるように、zの最適化関数を求める\n",
    "z_optimizer = torch.optim.Adam([z], lr=1e-3)\n",
    "\n",
    "\n",
    "# zを求める\n",
    "for epoch in range(5000+1):\n",
    "    fake_img = G_update(z)\n",
    "    loss, _, _ = Anomaly_score(x, fake_img, D_update, Lambda=0.1)\n",
    "\n",
    "    z_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    z_optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print('epoch {} || loss_total:{:.0f} '.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fofex37oNTR5",
    "outputId": "320b5428-ed6d-42d0-e308-92f1dce6669f"
   },
   "outputs": [],
   "source": [
    "# 画像を生成\n",
    "G_update.eval()\n",
    "fake_img = G_update(z)\n",
    "\n",
    "# 損失を求める\n",
    "loss, loss_each, residual_loss_each = Anomaly_score(\n",
    "    x, fake_img, D_update, Lambda=0.1)\n",
    "\n",
    "# 損失の計算。トータルの損失\n",
    "loss_each = loss_each.cpu().detach().numpy()\n",
    "print(\"total loss：\", np.round(loss_each, 0))\n",
    "\n",
    "# 画像を可視化\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 上段にテストデータを\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 下段に生成データを表示する\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    plt.imshow(fake_img[i][0].cpu().detach().numpy(), 'gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8v2SE8_6NTR6"
   },
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6-2_AnoGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
